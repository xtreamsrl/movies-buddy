{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# How Can We Represent Semantic? Embeddings 101"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "Since high school computer programming classes, everyone knows that computer can understand only numbers. So, how can LLM understand humans language? \n",
    "\n",
    "## A Bit of History\n",
    "\n",
    "A naive way to do this is to map every words of the dictionary to a number. That is, a sentence like \"Applied Machine Learning Days are a super cool conference\" became a list of integer\n",
    "```\n",
    "[10, 40, 5, 10, 7, 8, 90, 123, 2]\n",
    "```\n",
    "This is a very simple method, but for complex Natural Language Processing (NLP) tasks is not sufficient. Researchers in this field have developed during the years many different strategies to generate numerical reppresantation that include also semantic features of the language. In 2013, Word2Vec from Google make his first appereance on the stage introducing a method to generate dense vector representations, or embeddings, of words that capture a significant amount of language semantic. For example: \n",
    "```\n",
    "\"Queen\" = [0.3, 0.3, 0.2, ..., 0.3]\n",
    "\"King\" = [0.5, -0.3, 0.1, ..., 0.5]\n",
    "\"Man\" = [0.2, 0.95, 0.3, ..., 0.1]\n",
    "\"Woman\" = [0.56, -0.5, 0.32, ..., 0.1]\n",
    "```\n",
    "So, we have a multi-dimensional matematichal space where vectors close to each others represent words semantically similar. in the above example, the vectors representing \"Queen\" and \"Woman\", or \"King\" and \"Man\" are probably close to each others. One of the coolest consegunece of this is that we can apply mathematical operations to vector obtaining others vectors! \n",
    "\n",
    "```\n",
    "\"King\" - \"Man\" + \"Woman\" ~= \"Queen\"\n",
    "```\n",
    "\n",
    "## TODO: add here some of history after word to vec, sentences transformer etc.\n",
    "[...]\n",
    "\n",
    "\n",
    "But talk is cheap! Let's put the hands in the mud and make our computer understand language!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "# Every Good Craftsman Need Good Tools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "We import some useful python dependencies that we will need for executing this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import umap\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "\n",
    "from movie_buddy.preprocessing.movies_dataset import (\n",
    "    get_movies_dataset,\n",
    "    get_sentences_dataset,\n",
    ")\n",
    "from movie_buddy.preprocessing.utils import reduce_dimensions, add_umap_to_df\n",
    "from movie_buddy.preprocessing.visualization import plot_sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "# Let's Play With Sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "As we discussed early, we need to help our laptop to understand sentences. We talk about embeddings models, it seems a scary concept and it could be if we deal with all the details. Luckily someone did a lot of works for us, we can just donwload pre-trained sentence embedings model from HuggingFace repository:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = SentenceTransformer(\"sentence-transformers/all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_sent = encoder.encode(\"My first encoded sentence: AMLD are Cools\")\n",
    "print(\n",
    "    f\"First and last part of the resulting vector:\\n{encoded_sent[:5]} ... {encoded_sent[len(encoded_sent)-5:]}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "Congratulations! You have encoded your first sentence! \n",
    "\n",
    "Let's make a further step, we can embed multiple sentences: we have prepared a dataset of sentences regarding different fields raging from \"Nature and Enviroment\" to \"Sports\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences_df = get_sentences_dataset()\n",
    "sentences_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_sentences = encoder.encode(sentences_df[\"sentences\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_sentences.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced_encoded_sentences = reduce_dimensions(encoded_sentences)\n",
    "full_sentences_df = add_umap_to_df(sentences_df, reduced_encoded_sentences)\n",
    "\n",
    "# This is just to improve visualization\n",
    "full_sentences_df[\"short_sentences\"] = (\n",
    "    full_sentences_df[\"sentences\"].str.slice(0, 20) + \"...\"\n",
    ")\n",
    "full_sentences_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_sentences(full_sentences_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {},
   "source": [
    "Note that, encoder didn't know nothing about the field of the sentence, could you see some interesting pattern?\n",
    "\n",
    "Now, it is your turn! Add more sentences and try to guess in which zone of the plot will be positioned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "your_sentences = [\n",
    "    \"Schools are very important for our society\",\n",
    "    \"I run every day\",\n",
    "    \"AI will revoluzionize the computer science industry\",\n",
    "    # PUT YOUR SENTENCES DOWN THERE IN THE LIST\n",
    "    # |\n",
    "    # V\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "your_sentences_df = pd.DataFrame(your_sentences, columns=[\"sentences\"])\n",
    "your_sentences_df[\"field\"] = \"your_sentences\"\n",
    "\n",
    "full_your_sentences_df = pd.concat([sentences_df, your_sentences_df], ignore_index=True)\n",
    "full_your_sentences_df[\"short_sentences\"] = (\n",
    "    full_your_sentences_df[\"sentences\"].str.slice(0, 20) + \"...\"\n",
    ")\n",
    "your_encoded_sentences = encoder.encode(full_your_sentences_df[\"sentences\"])\n",
    "\n",
    "reduced_encoded_sentences = reduce_dimensions(your_encoded_sentences)\n",
    "full_your_sentences_df = add_umap_to_df(\n",
    "    full_your_sentences_df, reduced_encoded_sentences\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_sentences(full_your_sentences_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20",
   "metadata": {},
   "source": [
    "## What About Movies? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21",
   "metadata": {},
   "source": [
    "At the end of the day we want to build an AI movies assistant, so what about movies? \n",
    "\n",
    "We have a dataset containing some information such as title, overview, genre, release date about ~42000 movies. We can try to embed overviews and try to see if the encoder find some structure inside it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_df = get_movies_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(movies_df[\"overview\"].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_movies = encoder.encode(movies_df[\"overview\"].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "reducer = umap.UMAP()\n",
    "reduced_encoded_movies = reducer.fit_transform(encoded_movies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(reduced_encoded_movies.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_df[\"encoded_overview\"] = reduced_encoded_movies.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {},
   "outputs": [],
   "source": [
    "split = pd.DataFrame(movies_df[\"encoded_overview\"].tolist(), columns=[\"x\", \"y\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_df_joined = pd.concat(\n",
    "    [movies_df.reset_index(drop=True), split.reset_index(drop=True)],\n",
    "    axis=1,\n",
    ")\n",
    "movies_df_joined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter(\n",
    "    movies_df_joined.sample(5000),\n",
    "    x=\"x\",\n",
    "    y=\"y\",\n",
    "    color=\"genre\",\n",
    "    height=512,\n",
    "    hover_name=\"genre\",\n",
    "    hover_data={\"overview\": False, \"title\": True, \"x\": False, \"y\": False},\n",
    ")\n",
    "fig.update_layout(title_text=\"Which Movies Are Close?\", template=\"plotly_white\")\n",
    "fig.update_traces(textposition=\"top center\", marker=dict(size=5))\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
